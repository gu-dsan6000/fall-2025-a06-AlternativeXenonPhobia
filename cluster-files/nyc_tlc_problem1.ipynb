{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Daily Summaries of Key Metrics for NYC TLC Data\n",
    "\n",
    "This notebook downloads 6 months of NYC TLC data (Jan-June 2021), combines them into a single DataFrame, and calculates daily summaries.\n",
    "\n",
    "## Requirements\n",
    "1. Derive `dt_year`, `dt_month`, `dt_day` from `tpep_pickup_datetime`\n",
    "2. Filter for year 2021\n",
    "3. Calculate daily summaries:\n",
    "   - Number of trips\n",
    "   - Average trip_distance\n",
    "   - Max mta_tax\n",
    "   - 95th percentile of fare_amount\n",
    "   - Min tip_amount\n",
    "   - Average passenger_count (rounded up)\n",
    "4. Sort by dt_year, dt_month, dt_day in descending order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    year, month, dayofmonth,\n",
    "    avg, count, max as spark_max, min as spark_min,\n",
    "    expr, ceil, percentile_approx\n",
    ")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging with basicConfig\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Set the log level to INFO\n",
    "    # Define log message format\n",
    "    format=\"%(asctime)s,p%(process)s,{%(filename)s:%(lineno)d},%(levelname)s,%(message)s\",\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Spark Session\n",
    "\n",
    "This cell creates a Spark session optimized for Problem 1 with:\n",
    "- 4GB driver memory\n",
    "- Local execution using all available cores\n",
    "- Adaptive query execution enabled\n",
    "- Arrow optimization for Pandas conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/10/06 15:00:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2025-10-06 15:00:28,638,p17536,{3812127214.py:23},INFO,Spark session created successfully for Problem 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Spark session created successfully!\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Problem1_DailySummaries\")\n",
    "\n",
    "    # Memory Configuration\n",
    "    .config(\"spark.driver.memory\", \"4g\")\n",
    "    .config(\"spark.driver.maxResultSize\", \"2g\")\n",
    "\n",
    "    # Performance settings for local execution\n",
    "    .config(\"spark.master\", \"local[*]\")  # Use all available cores\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\")\n",
    "\n",
    "    # Serialization\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
    "\n",
    "    # Arrow optimization for Pandas conversion\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "logger.info(\"Spark session created successfully for Problem 1\")\n",
    "print(\"✅ Spark session created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download NYC TLC Data\n",
    "\n",
    "This cell downloads 6 months of NYC TLC data (January-June 2021) from S3.\n",
    "Files are saved to the `data/` directory and are skipped if already downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 15:00:39,230,p17536,{3534718927.py:4},INFO,Starting download of 3 months of NYC TLC data\n",
      "2025-10-06 15:00:39,232,p17536,{3534718927.py:33},INFO,Starting S3 download for month 01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading 3 months of NYC TLC data...\n",
      "============================================================\n",
      "  Downloading month 01/2021...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 15:00:40,848,p17536,{3534718927.py:40},INFO,Successfully downloaded month 01: 20.7 MB\n",
      "2025-10-06 15:00:40,849,p17536,{3534718927.py:33},INFO,Starting S3 download for month 02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✅ Downloaded: 20.7 MB\n",
      "  Downloading month 02/2021...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 15:00:42,219,p17536,{3534718927.py:40},INFO,Successfully downloaded month 02: 20.8 MB\n",
      "2025-10-06 15:00:42,220,p17536,{3534718927.py:33},INFO,Starting S3 download for month 03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✅ Downloaded: 20.8 MB\n",
      "  Downloading month 03/2021...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 15:00:43,680,p17536,{3534718927.py:40},INFO,Successfully downloaded month 03: 28.6 MB\n",
      "2025-10-06 15:00:43,682,p17536,{3534718927.py:55},INFO,Download complete: 3 files successfully downloaded, total size: 70.1 MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✅ Downloaded: 28.6 MB\n",
      "\n",
      "✅ Downloaded 3 files, total size: 70.1 MB\n",
      "✅ Ready to process 3 data files\n"
     ]
    }
   ],
   "source": [
    "def download_monthly_data(months_to_download):\n",
    "    \"\"\"Download multiple months of NYC TLC data from S3.\"\"\"\n",
    "\n",
    "    logger.info(f\"Starting download of {len(months_to_download)} months of NYC TLC data\")\n",
    "    print(f\"\\nDownloading {len(months_to_download)} months of NYC TLC data...\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    downloaded_files = []\n",
    "    total_size = 0\n",
    "\n",
    "    # Create data directory if it doesn't exist\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "    for month_num in months_to_download:\n",
    "        month_str = f\"{month_num:02d}\"\n",
    "        s3_path = f\"s3://bigdatateaching/nyc_tlc/trip_data/yyyy=2021/yellow_tripdata_2021-{month_str}.parquet\"\n",
    "        local_path = f\"data/yellow_tripdata_2021-{month_str}.parquet\"\n",
    "\n",
    "        print(f\"  Downloading month {month_str}/2021...\")\n",
    "        logger.debug(f\"Processing month {month_str}: S3 path={s3_path}, local path={local_path}\")\n",
    "\n",
    "        try:\n",
    "            # Check if file already exists\n",
    "            if os.path.exists(local_path):\n",
    "                file_size = os.path.getsize(local_path)\n",
    "                logger.info(f\"Month {month_str} file already exists locally: {file_size/1024/1024:.1f} MB\")\n",
    "                print(f\"    ✅ Already exists: {file_size/1024/1024:.1f} MB\")\n",
    "                downloaded_files.append(local_path)\n",
    "                total_size += file_size\n",
    "                continue\n",
    "\n",
    "            # Download from S3\n",
    "            logger.info(f\"Starting S3 download for month {month_str}\")\n",
    "            result = subprocess.run([\n",
    "                \"aws\", \"s3\", \"cp\", s3_path, local_path\n",
    "            ], capture_output=True, text=True, timeout=600)\n",
    "\n",
    "            if result.returncode == 0:\n",
    "                file_size = os.path.getsize(local_path)\n",
    "                logger.info(f\"Successfully downloaded month {month_str}: {file_size/1024/1024:.1f} MB\")\n",
    "                print(f\"    ✅ Downloaded: {file_size/1024/1024:.1f} MB\")\n",
    "                downloaded_files.append(local_path)\n",
    "                total_size += file_size\n",
    "            else:\n",
    "                logger.error(f\"Failed to download month {month_str}: {result.stderr}\")\n",
    "                print(f\"    ❌ Failed: {result.stderr}\")\n",
    "\n",
    "        except subprocess.TimeoutExpired:\n",
    "            logger.error(f\"Download timeout for month {month_str}\")\n",
    "            print(f\"    ❌ Download timed out\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Unexpected error downloading month {month_str}: {str(e)}\")\n",
    "            print(f\"    ❌ Error: {str(e)}\")\n",
    "\n",
    "    logger.info(f\"Download complete: {len(downloaded_files)} files successfully downloaded, total size: {total_size/1024/1024:.1f} MB\")\n",
    "    print(f\"\\n✅ Downloaded {len(downloaded_files)} files, total size: {total_size/1024/1024:.1f} MB\")\n",
    "    return downloaded_files\n",
    "\n",
    "\n",
    "# Download 6 months of data (January to June 2021)\n",
    "months_to_download = [1, 2, 3]\n",
    "data_files = download_monthly_data(months_to_download)\n",
    "\n",
    "if len(data_files) == 0:\n",
    "    print(\"❌ No data files available. Cannot proceed with analysis\")\n",
    "else:\n",
    "    print(f\"✅ Ready to process {len(data_files)} data files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data into Spark DataFrame\n",
    "\n",
    "Read all downloaded parquet files into a single Spark DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 15:00:47,331,p17536,{1907117768.py:1},INFO,Reading 3 parquet files into single DataFrame\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading all data files into a single DataFrame...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 15:00:55,153,p17536,{1907117768.py:6},INFO,Successfully loaded 4,666,630 total rows from 3 files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 4,666,630 total rows from 3 files\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Reading {len(data_files)} parquet files into single DataFrame\")\n",
    "print(\"Reading all data files into a single DataFrame...\")\n",
    "nyc_tlc = spark.read.parquet(*data_files)\n",
    "\n",
    "total_rows = nyc_tlc.count()\n",
    "logger.info(f\"Successfully loaded {total_rows:,} total rows from {len(data_files)} files\")\n",
    "print(f\"✅ Loaded {total_rows:,} total rows from {len(data_files)} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data Schema\n",
    "\n",
    "Let's examine the structure of the dataset before we begin our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: long (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- passenger_count: double (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: double (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the schema\n",
    "nyc_tlc.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample records from the dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|2       |2021-03-01 00:22:02 |2021-03-01 00:23:22  |1.0            |0.0          |1.0       |N                 |264         |264         |2           |3.0        |0.5  |0.5    |0.0       |0.0         |0.3                  |4.3         |0.0                 |NULL       |\n",
      "|2       |2021-03-01 00:24:48 |2021-03-01 00:24:56  |1.0            |0.0          |1.0       |N                 |152         |152         |2           |2.5        |0.5  |0.5    |0.0       |0.0         |0.3                  |3.8         |0.0                 |NULL       |\n",
      "|2       |2021-03-01 00:25:17 |2021-03-01 00:31:01  |1.0            |0.0          |1.0       |N                 |152         |152         |2           |3.5        |0.5  |0.5    |0.0       |0.0         |0.3                  |4.8         |0.0                 |NULL       |\n",
      "|1       |2021-03-01 00:07:40 |2021-03-01 00:31:23  |0.0            |16.5         |4.0       |N                 |138         |265         |1           |51.0       |0.5  |0.5    |11.65     |6.12        |0.3                  |70.07       |0.0                 |NULL       |\n",
      "|2       |2021-03-01 00:02:13 |2021-03-01 00:06:01  |1.0            |1.13         |1.0       |N                 |68          |264         |1           |5.5        |0.5  |0.5    |1.86      |0.0         |0.3                  |11.16       |2.5                 |NULL       |\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Show sample records\n",
    "print(\"Sample records from the dataset:\")\n",
    "nyc_tlc.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Derive Date Columns\n",
    "\n",
    "Extract year, month, and day from the `tpep_pickup_datetime` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 15:01:02,786,p17536,{4229086798.py:1},INFO,Step 1: Deriving date columns from tpep_pickup_datetime\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Deriving date columns from tpep_pickup_datetime...\n",
      "✅ Date columns added\n",
      "\n",
      "Sample with date columns:\n",
      "+--------------------+-------+--------+------+\n",
      "|tpep_pickup_datetime|dt_year|dt_month|dt_day|\n",
      "+--------------------+-------+--------+------+\n",
      "| 2021-03-01 00:22:02|   2021|       3|     1|\n",
      "| 2021-03-01 00:24:48|   2021|       3|     1|\n",
      "| 2021-03-01 00:25:17|   2021|       3|     1|\n",
      "| 2021-03-01 00:07:40|   2021|       3|     1|\n",
      "| 2021-03-01 00:02:13|   2021|       3|     1|\n",
      "+--------------------+-------+--------+------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Step 1: Deriving date columns from tpep_pickup_datetime\")\n",
    "print(\"Step 1: Deriving date columns from tpep_pickup_datetime...\")\n",
    "\n",
    "nyc_tlc = (nyc_tlc\n",
    "    .withColumn(\"dt_year\", year(\"tpep_pickup_datetime\"))\n",
    "    .withColumn(\"dt_month\", month(\"tpep_pickup_datetime\"))\n",
    "    .withColumn(\"dt_day\", dayofmonth(\"tpep_pickup_datetime\"))\n",
    ")\n",
    "\n",
    "print(\"✅ Date columns added\")\n",
    "print(\"\\nSample with date columns:\")\n",
    "nyc_tlc.select(\"tpep_pickup_datetime\", \"dt_year\", \"dt_month\", \"dt_day\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Filter for Year 2021\n",
    "\n",
    "Ensure we only include data from 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 15:01:06,416,p17536,{216681216.py:1},INFO,Step 2: Filtering data for year 2021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Filtering data for year 2021...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 15:01:09,597,p17536,{216681216.py:7},INFO,Filtered dataset to 4,666,578 rows for year 2021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Filtered to 4,666,578 rows for year 2021\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Step 2: Filtering data for year 2021\")\n",
    "print(\"Step 2: Filtering data for year 2021...\")\n",
    "\n",
    "nyc_tlc_2021 = nyc_tlc.filter(nyc_tlc.dt_year == 2021)\n",
    "filtered_rows = nyc_tlc_2021.count()\n",
    "\n",
    "logger.info(f\"Filtered dataset to {filtered_rows:,} rows for year 2021\")\n",
    "print(f\"✅ Filtered to {filtered_rows:,} rows for year 2021\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Calculate Daily Summaries\n",
    "\n",
    "Group by date and calculate the required metrics:\n",
    "- Number of trips\n",
    "- Average trip distance\n",
    "- Maximum MTA tax\n",
    "- 95th percentile of fare amount\n",
    "- Minimum tip amount\n",
    "- Average passenger count (rounded up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 15:01:10,586,p17536,{2923183392.py:1},INFO,Step 3: Calculating daily summaries with aggregations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Calculating daily summaries...\n",
      "✅ Daily summaries calculated\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Step 3: Calculating daily summaries with aggregations\")\n",
    "print(\"Step 3: Calculating daily summaries...\")\n",
    "\n",
    "daily_averages = (nyc_tlc_2021\n",
    "    .groupBy(\"dt_year\", \"dt_month\", \"dt_day\")\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"num_trips\"),\n",
    "        avg(\"trip_distance\").alias(\"mean_trip_distance\"),\n",
    "        spark_max(\"mta_tax\").alias(\"max_mta_tax\"),\n",
    "        expr(\"percentile_approx(fare_amount, 0.95)\").alias(\"q95_fare_amount\"),\n",
    "        spark_min(\"tip_amount\").alias(\"min_tip_amount\"),\n",
    "        ceil(avg(\"passenger_count\")).alias(\"mean_passenger_count\")\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"✅ Daily summaries calculated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Sort by Date (Descending)\n",
    "\n",
    "Sort the results by year, month, and day in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 15:01:16,383,p17536,{2655154960.py:1},INFO,Step 4: Sorting results by date in descending order\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4: Sorting by date (descending)...\n",
      "✅ Results sorted\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Step 4: Sorting results by date in descending order\")\n",
    "print(\"Step 4: Sorting by date (descending)...\")\n",
    "\n",
    "daily_averages = daily_averages.orderBy(\n",
    "    \"dt_year\", \"dt_month\", \"dt_day\",\n",
    "    ascending=[False, False, False]\n",
    ")\n",
    "\n",
    "print(\"✅ Results sorted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Display Results\n",
    "\n",
    "View the top daily summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 15:01:19,545,p17536,{3530814441.py:1},INFO,Step 5: Displaying results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 daily summaries (sorted in descending order):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+---------+------------------+-----------+---------------+--------------+--------------------+\n",
      "|dt_year|dt_month|dt_day|num_trips|mean_trip_distance|max_mta_tax|q95_fare_amount|min_tip_amount|mean_passenger_count|\n",
      "+-------+--------+------+---------+------------------+-----------+---------------+--------------+--------------------+\n",
      "|   2021|       5|    27|        3|2.7566666666666664|        0.5|           14.0|           0.0|                   1|\n",
      "|   2021|       5|     5|        4|             1.245|        0.5|            9.5|           0.0|                   1|\n",
      "|   2021|       4|    14|        3|1.3633333333333333|        0.5|           10.0|           0.0|                   1|\n",
      "|   2021|       4|     1|        5|3.7840000000000003|        0.5|           22.5|           0.0|                   2|\n",
      "|   2021|       3|    31|    67533|3.0777288140612673|        3.3|          35.06|        -30.56|                   2|\n",
      "|   2021|       3|    30|    66702|2.9260648856106313|        0.5|           35.0|         -1.36|                   2|\n",
      "|   2021|       3|    29|    58127| 4.058761332943358|        0.5|          35.95|         -0.86|                   2|\n",
      "|   2021|       3|    28|    40404|3.3863572913572835|        0.5|           42.5|          -1.0|                   2|\n",
      "|   2021|       3|    27|    67392|2.9553249643874624|        3.3|           32.5|         -0.88|                   2|\n",
      "|   2021|       3|    26|    73535| 4.345160671788945|        0.5|           34.5|        -13.82|                   2|\n",
      "|   2021|       3|    25|    69841|4.2637642645437825|        0.5|          33.85|         -0.86|                   2|\n",
      "|   2021|       3|    24|    68659| 3.630117391747603|        0.5|          32.59|          -5.0|                   2|\n",
      "|   2021|       3|    23|    63548| 4.843450462642418|        0.5|          33.58|         -1.14|                   2|\n",
      "|   2021|       3|    22|    59959| 5.658548674927885|        0.5|          36.88|         -0.86|                   2|\n",
      "|   2021|       3|    21|    45124|3.3174820494636914|        0.5|           40.2|         -10.0|                   2|\n",
      "|   2021|       3|    20|    61538|  4.00779940849554|        0.5|           32.0|         -0.66|                   2|\n",
      "|   2021|       3|    19|    74427|  3.49798137772582|        0.5|           32.5|         -0.76|                   2|\n",
      "|   2021|       3|    18|    71539| 5.373893400802395|        0.5|           32.5|         -1.08|                   2|\n",
      "|   2021|       3|    17|    71510| 5.342838204446938|        0.5|           31.5|        -16.32|                   2|\n",
      "|   2021|       3|    16|    65479| 4.627389697460226|        0.5|           33.2|        -12.31|                   2|\n",
      "+-------+--------+------+---------+------------------+-----------+---------------+--------------+--------------------+\n",
      "only showing top 20 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 15:01:32,147,p17536,{3530814441.py:7},INFO,Calculated summaries for 94 days\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Calculated summaries for 94 days\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Step 5: Displaying results\")\n",
    "print(\"\\nTop 20 daily summaries (sorted in descending order):\")\n",
    "daily_averages.show(20)\n",
    "\n",
    "# Get total number of days\n",
    "total_days = daily_averages.count()\n",
    "logger.info(f\"Calculated summaries for {total_days} days\")\n",
    "print(f\"\\n✅ Calculated summaries for {total_days} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Convert to Pandas DataFrame\n",
    "\n",
    "Convert the Spark DataFrame to Pandas for easier manipulation and export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 15:01:41,602,p17536,{969615932.py:1},INFO,Step 6: Converting Spark DataFrame to Pandas DataFrame\n",
      "/home/ubuntu/lab-spark-cluster/.venv/lib/python3.12/site-packages/pyspark/sql/pandas/conversion.py:95: UserWarning: toPandas attempted Arrow optimization because 'spark.sql.execution.arrow.pyspark.enabled' is set to true; however, failed by the reason below:\n",
      "  [PACKAGE_NOT_INSTALLED] PyArrow >= 11.0.0 must be installed; however, it was not found.\n",
      "Attempting non-optimization as 'spark.sql.execution.arrow.pyspark.fallback.enabled' is set to true.\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6: Converting to Pandas DataFrame...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Converted to Pandas\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt_year</th>\n",
       "      <th>dt_month</th>\n",
       "      <th>dt_day</th>\n",
       "      <th>num_trips</th>\n",
       "      <th>mean_trip_distance</th>\n",
       "      <th>max_mta_tax</th>\n",
       "      <th>q95_fare_amount</th>\n",
       "      <th>min_tip_amount</th>\n",
       "      <th>mean_passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>2.756667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1.245000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>9.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>1.363333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3.784000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>22.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>67533</td>\n",
       "      <td>3.077729</td>\n",
       "      <td>3.3</td>\n",
       "      <td>35.06</td>\n",
       "      <td>-30.56</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>66702</td>\n",
       "      <td>2.926065</td>\n",
       "      <td>0.5</td>\n",
       "      <td>35.00</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>58127</td>\n",
       "      <td>4.058761</td>\n",
       "      <td>0.5</td>\n",
       "      <td>35.95</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>40404</td>\n",
       "      <td>3.386357</td>\n",
       "      <td>0.5</td>\n",
       "      <td>42.50</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>67392</td>\n",
       "      <td>2.955325</td>\n",
       "      <td>3.3</td>\n",
       "      <td>32.50</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>73535</td>\n",
       "      <td>4.345161</td>\n",
       "      <td>0.5</td>\n",
       "      <td>34.50</td>\n",
       "      <td>-13.82</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dt_year  dt_month  dt_day  num_trips  mean_trip_distance  max_mta_tax  \\\n",
       "0     2021         5      27          3            2.756667          0.5   \n",
       "1     2021         5       5          4            1.245000          0.5   \n",
       "2     2021         4      14          3            1.363333          0.5   \n",
       "3     2021         4       1          5            3.784000          0.5   \n",
       "4     2021         3      31      67533            3.077729          3.3   \n",
       "5     2021         3      30      66702            2.926065          0.5   \n",
       "6     2021         3      29      58127            4.058761          0.5   \n",
       "7     2021         3      28      40404            3.386357          0.5   \n",
       "8     2021         3      27      67392            2.955325          3.3   \n",
       "9     2021         3      26      73535            4.345161          0.5   \n",
       "\n",
       "   q95_fare_amount  min_tip_amount  mean_passenger_count  \n",
       "0            14.00            0.00                     1  \n",
       "1             9.50            0.00                     1  \n",
       "2            10.00            0.00                     1  \n",
       "3            22.50            0.00                     2  \n",
       "4            35.06          -30.56                     2  \n",
       "5            35.00           -1.36                     2  \n",
       "6            35.95           -0.86                     2  \n",
       "7            42.50           -1.00                     2  \n",
       "8            32.50           -0.88                     2  \n",
       "9            34.50          -13.82                     2  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.info(\"Step 6: Converting Spark DataFrame to Pandas DataFrame\")\n",
    "print(\"Step 6: Converting to Pandas DataFrame...\")\n",
    "\n",
    "pandas_df = daily_averages.toPandas()\n",
    "print(\"✅ Converted to Pandas\")\n",
    "\n",
    "# Display the Pandas DataFrame\n",
    "pandas_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics\n",
    "\n",
    "Display key statistics about the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PROBLEM 1 COMPLETED - Summary Statistics\n",
      "============================================================\n",
      "Total rows processed: 4,666,578\n",
      "Days with data: 94\n",
      "Date range: 01/01/2021 to 05/31/2021\n",
      "Total trips: 4,666,578\n",
      "Average daily trips: 49644\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"PROBLEM 1 COMPLETED - Summary Statistics\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total rows processed: {filtered_rows:,}\")\n",
    "print(f\"Days with data: {total_days}\")\n",
    "print(f\"Date range: {pandas_df['dt_month'].min():02d}/{pandas_df['dt_day'].min():02d}/2021 to {pandas_df['dt_month'].max():02d}/{pandas_df['dt_day'].max():02d}/2021\")\n",
    "print(f\"Total trips: {pandas_df['num_trips'].sum():,}\")\n",
    "print(f\"Average daily trips: {pandas_df['num_trips'].mean():.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Sample Results\n",
    "\n",
    "View formatted details for the first few days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Sample Results (first 5 rows):\n",
      "============================================================\n",
      "Year: 2021, Month: 05, Day: 27\n",
      "  Trips: 3\n",
      "  Avg Distance: 2.76 miles\n",
      "  Max MTA Tax: $0.50\n",
      "  95th Percentile Fare: $14.00\n",
      "  Min Tip: $0.00\n",
      "  Avg Passengers: 1\n",
      "----------------------------------------\n",
      "Year: 2021, Month: 05, Day: 05\n",
      "  Trips: 4\n",
      "  Avg Distance: 1.25 miles\n",
      "  Max MTA Tax: $0.50\n",
      "  95th Percentile Fare: $9.50\n",
      "  Min Tip: $0.00\n",
      "  Avg Passengers: 1\n",
      "----------------------------------------\n",
      "Year: 2021, Month: 04, Day: 14\n",
      "  Trips: 3\n",
      "  Avg Distance: 1.36 miles\n",
      "  Max MTA Tax: $0.50\n",
      "  95th Percentile Fare: $10.00\n",
      "  Min Tip: $0.00\n",
      "  Avg Passengers: 1\n",
      "----------------------------------------\n",
      "Year: 2021, Month: 04, Day: 01\n",
      "  Trips: 5\n",
      "  Avg Distance: 3.78 miles\n",
      "  Max MTA Tax: $0.50\n",
      "  95th Percentile Fare: $22.50\n",
      "  Min Tip: $0.00\n",
      "  Avg Passengers: 2\n",
      "----------------------------------------\n",
      "Year: 2021, Month: 03, Day: 31\n",
      "  Trips: 67,533\n",
      "  Avg Distance: 3.08 miles\n",
      "  Max MTA Tax: $3.30\n",
      "  95th Percentile Fare: $35.06\n",
      "  Min Tip: $-30.56\n",
      "  Avg Passengers: 2\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Sample Results (first 5 rows):\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "sample_df = pandas_df.head(5)\n",
    "for _, row in sample_df.iterrows():\n",
    "    print(f\"Year: {int(row['dt_year'])}, Month: {int(row['dt_month']):02d}, Day: {int(row['dt_day']):02d}\")\n",
    "    print(f\"  Trips: {int(row['num_trips']):,}\")\n",
    "    print(f\"  Avg Distance: {row['mean_trip_distance']:.2f} miles\")\n",
    "    print(f\"  Max MTA Tax: ${row['max_mta_tax']:.2f}\")\n",
    "    print(f\"  95th Percentile Fare: ${row['q95_fare_amount']:.2f}\")\n",
    "    print(f\"  Min Tip: ${row['min_tip_amount']:.2f}\")\n",
    "    print(f\"  Avg Passengers: {row['mean_passenger_count']:.0f}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup: Stop Spark Session\n",
    "\n",
    "Remember to stop the Spark session when you're done to free up resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Spark session stopped\n"
     ]
    }
   ],
   "source": [
    "spark.stop()\n",
    "print(\"✅ Spark session stopped\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab-spark-cluster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
